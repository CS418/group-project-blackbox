{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CS418/group-project-blackbox/blob/main/Spotify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Introduction**\n",
        "Predicting the popularity of songs based purely on song metrics such as key, danceability, and acousticness. Currently, being able to predict that something might be popular beforehand is an important research subject for every industry. It also has recently become a very important subject for the growing and competitive music industry as well. Since wide use of digital music platforms (Spotify, Billboard, Lastfm), data can be easily reached and the listening behaviors of the listeners can be easily observed. This provides convenience in forecasting techniques and it is also frequently used in recommendation systems."
      ],
      "metadata": {
        "id": "a5vGwxaVuLIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Any changes?**\n",
        "Yes, we are currently focussing on the first hypothesis & trying to understand user’s usability aspects more than data over continents.\n",
        "We are starting with understanding what features make a user end up liking a song.\n",
        "The hypothesis we are trying to gain insight into is \n",
        "Chances of a user liking a song based on his current favorite song.\n"
      ],
      "metadata": {
        "id": "tmOm14vGvPDN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve65bqmSixUY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction\n",
        "\n",
        "\n",
        "### Extract Song titles from my Playlist using Spotify API\n",
        "### API :  GET https://api.spotify.com/v1/playlists/{playlist_id}/tracks\n"
      ],
      "metadata": {
        "id": "q-kXPO3Ht4gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import json\n",
        "  \n",
        "f = open('gdrive/My Drive/playlist.json')\n",
        "  \n",
        "data = json.load(f)\n",
        "  \n",
        "len(data['items'])\n",
        "track_ids_names=[]\n",
        "track_ids=[]\n",
        "for d in data['items']:\n",
        "  track_ids_names.append({'id':d['track']['id'],'name':d['track']['name']})\n",
        "  track_ids.append(d['track']['id'])\n",
        "track_ids_names"
      ],
      "metadata": {
        "id": "GJdMIvv9RZN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract track features of all the songs in the playlist\n"
      ],
      "metadata": {
        "id": "voM8HX1wv2tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    'Accept': 'application/json',\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer BQApG4L-oRYsrw68aQ4fsKy-Ua_FbeDxvIrh9WR1EmaH3HSG80VJH4m37j5Ivrbff2ON5znOxve8vlhJXMjWpNTzWK3Fd5czqD_AvKVc3kO18pKOGEaiw0NHHYPhez2-qpVt2jMAFGzo-40VfFBtpCT1hyg2mZ-xJ58gaqaHiyRMF1I21TlLWjwt_-R4gJvsZeY',\n",
        "}\n",
        "\n",
        "\n",
        "song_features = []\n",
        "for t in track_ids:\n",
        "  response = requests.get('https://api.spotify.com/v1/audio-features/'+t, headers=headers)\n",
        "  song_features.append(response.json())\n",
        "\n",
        "print(song_features)\n",
        "\n",
        "\n",
        "print(track_ids_names)"
      ],
      "metadata": {
        "id": "IVn2UZHovr0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('gdrive/My Drive/track_features.json', 'w') as f:\n",
        "    json.dump(song_features, f)\n",
        "\n",
        "print(song_features)"
      ],
      "metadata": {
        "id": "JufH_woUwW6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json('gdrive/My Drive/track_features.json')\n",
        "\n",
        "df.to_csv('gdrive/My Drive/extracted_track_features.csv', encoding='utf-8', index=False)\n",
        "\n",
        "# We drop all the features which are meta data in the dataset \n",
        "\n",
        "df = df.drop(columns=['type', 'id','uri','track_href','analysis_url'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "NemgaP57wXkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing\n"
      ],
      "metadata": {
        "id": "m-wJ-jKAwe7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since Instrumentalness and time_signature do not have any impact on the data, we remove the features\n",
        "\n",
        "df = df.drop(columns=['instrumentalness','time_signature'])\n",
        "\n",
        "df.columns\n",
        "df['liked'] = [1]*100\n",
        "df"
      ],
      "metadata": {
        "id": "ozMXvxbDwlKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "\n",
        "df.to_csv('gdrive/My Drive/cleaned_liked_songs.csv', encoding='utf-8', index=False)\n"
      ],
      "metadata": {
        "id": "iXfu7uYywsgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We inserted the 95 most non liked songs features to the data after querying †˙e Spotify API to the data\n",
        "\n",
        "\n",
        "data=pd.read_csv('gdrive/My Drive/cleaned_liked_disliked_songs.csv').dropna(axis=1, how='all')\n",
        "data.head()\n",
        "\n",
        "#  The model will somewhat think they only have to learn what is a liked song because they'll only see them at the beginning.So we need to shuffle the songs\n",
        "\n",
        "data = data.sample(frac=1)\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "AyV-qg1Tww5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  The model will somewhat think they only have to learn what is a liked song because they'll only see them at the beginning.So we need to shuffle the songs\n",
        "\n",
        "data = data.sample(frac=1)\n",
        "data\n",
        "\n",
        "data.to_csv('gdrive/My Drive/final_data_spotify.csv', encoding='utf-8', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8o-vWh-owy3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data is cleaned and ready to use"
      ],
      "metadata": {
        "id": "DyQr9Bqbw1Fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA\n",
        "## The main features we are getting in this dataset are\n",
        "### acousticness : A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
        "\n",
        "### danceability : Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
        "\n",
        "### duration_ms : The duration of the track in milliseconds.\n",
        "\n",
        "### energy : Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
        "\n",
        "\n",
        "### key : The key the track is in. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.\n",
        "\n",
        "### liveness : Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n",
        "\n",
        "### loudness : The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n",
        "\n",
        "###mode : Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
        "\n",
        "### speechiness : Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n",
        "### tempo : The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n",
        "\n",
        "### valence : A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
        "\n",
        "### And the variable that has to be predicted :\n",
        "### liked : 1 for liked songs , 0 for disliked songs\n"
      ],
      "metadata": {
        "id": "eSWUgMVCxPKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('gdrive/My Drive/final_data_spotify.csv').dropna(axis=1, how='all')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "QTumYHtMxNey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "data.info()\n",
        "data.isnull().sum()\n",
        "\n",
        "data['liked'].value_counts()"
      ],
      "metadata": {
        "id": "k7jTtMjJyM2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data.corr()[[\"liked\"]]\n",
        "fig, ax = plt.subplots(figsize=(10,10)) \n",
        "sns.heatmap(\n",
        "    corr, \n",
        "    annot=True,\n",
        "    ax=ax\n",
        ");"
      ],
      "metadata": {
        "id": "ltmdeH8lyRKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I like songs which are:\n",
        "  1. acoustic \n",
        "  2. melodic(mode)\n",
        "  3. Loud\n",
        "  4. Key\n",
        "\n",
        "Songs I dont like:\n",
        "  1. high energy\n",
        "  2. short duration"
      ],
      "metadata": {
        "id": "FYI9IVmfyZ8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  The model will somewhat think they only have to learn what is a liked song because they'll only see them at the beginning.So we need to shuffle the songs\n",
        "\n",
        "data = data.sample(frac=1)\n",
        "data\n"
      ],
      "metadata": {
        "id": "r9wFo4ghya-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "sj5qSW3_yfrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score , roc_auc_score , confusion_matrix\n",
        "\n",
        "X = data.drop('liked' , axis = 1)\n",
        "y = data['liked']\n",
        "\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2)\n",
        "\n",
        "print(\"the shapes of x-train and x-test are : \" , X_train.shape , X_test.shape)\n",
        "print(\"the shapes of y-train and y-test are : \" , y_train.shape , y_test.shape)\n"
      ],
      "metadata": {
        "id": "wF2jwSeGyXyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier , plot_tree\n",
        "\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train , y_train)\n",
        "\n",
        "y_preds_dt = dt_clf.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy Score of the Decision Tree Model\" , accuracy_score(y_test , y_preds_dt))\n"
      ],
      "metadata": {
        "id": "8Kx4cqO0yiLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm  = confusion_matrix(y_test , y_preds_dt)\n",
        "\n",
        "x_axis_labels = [\"Yes\" , \"No\"]\n",
        "y_axis_labels = [\"Yes\" , \"No\"]\n",
        "\n",
        "f , ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(cm , annot=True, linewidths=0.2 , linecolor=\"black\" , fmt=\".0f\" , ax=ax , cmap=\"Greens\" , \n",
        "           xticklabels=x_axis_labels , yticklabels=y_axis_labels)\n",
        "plt.xlabel(\"PREDICTED LABEL\")\n",
        "plt.ylabel(\"TRUE LABEL\")\n",
        "plt.title(\"Confusin Matrix Of Decision Tree Model\")"
      ],
      "metadata": {
        "id": "X-fgiB7My9jp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}